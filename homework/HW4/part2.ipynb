{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Doc2Vec\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1056)>\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import gensim\n",
    "import nltk\n",
    "from materials.code import utils\n",
    "importlib.reload(utils)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# IMPORT SOME BASIC TOOLS:\n",
    "from pprint import pprint\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "###  Introduction\n",
    "Recall that an embedding is just another way of representing our text data. In the case of word2vec, we were trying to learn an embedding that allowed us to relate the [one-hot](https://en.wikipedia.org/wiki/One-hot) representations of a given word, to the one-hot representations of the context words. Because of this, word2vec provides a single vector representation for each distinct word in our vocabulary. This could be useful if we wanted to discover similar words based on their contextual usage, or to compare corpora based on the embeddings of their individual words. \n",
    "\n",
    "But word-level vector representations may not be the best way to represent our text in all circumstances. Consider the problem of classifying the Rotten Tomatoes movie reviews; each review has a *varying number of words* and we would like to use **all these words together** when classifying the reviews. So, if we represent the sentences as the set of word vectors that comprise it, we'll have (for each sentence) a matrix with as many rows as words, and as many columns as the embedding size. The problem is that (most) classifiers expect a fixed size input [tensor](https://en.wikipedia.org/wiki/Tensor#:~:text=In%20mathematics%2C%20a%20tensor%20is,scalars%2C%20and%20even%20other%20tensors.).   \n",
    "\n",
    "So, how can we solve this problem? Doc2Vec is a simple modification to the word2vec algorithm proposed by [[Mikolov, 2014]](https://arxiv.org/pdf/1405.4053.pdf) that creates a fixed-length numeric representation of a document (e.g. a movie review) regardless of the document's length. Technically, this is accomplished by providing a one-hot `document_id` as one of the inputs to word2vec when training, alongside the context. Effectively, doc2vec, combines the semantic meaning for each documents words. You can read Mikolov's paper for the full technical details, or see [this blog](https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e) for a more intuitive explanation for how doc2vec differs from word2vec. \n",
    "\n",
    "**Note:** Doc2Vec is just one approach to combining the word2vec vectors and it is by no means authoritative or \"the best\". There are several simple alternatives: we could take a simple average of the word vectors, or we could represent the sentences as a (very large and very sparse) bag-of-word-vectors; like any solution, these have their pros and cons. I bring this to your attention because it's important to understand that there is no such thing as a \"good\" or \"bad\" method; The appropriate method depends on the problem you are trying to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "In this component of the tutorial, we will train a doc2vec model. To begin, let's import the Rotten Tomatoes Dataset again, and break it into `sentences`, and class labels `y`, and tokenize the sentences using the `nltk` tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes_movie_review (/Users/ghamut/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/9198dbc50858df8bdb0d5f18ccaf33125800af96ad8434bc8b829918c987ee8a)\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------\n",
    "# Import the rotton tomatoes dataset:\n",
    "#-------------------------------------------------\n",
    "from datasets import load_dataset\n",
    "dataset   = load_dataset('rotten_tomatoes')\n",
    "\n",
    "#-------------------------------------------------\n",
    "# Flatten out the dataset into a list of sentences and outcome, y\n",
    "#-------------------------------------------------\n",
    "sentences = dataset['train']['text']  + dataset['validation']['text'] + dataset['test']['text']\n",
    "y         = dataset['train']['label'] + dataset['validation']['label'] + dataset['test']['label']\n",
    "\n",
    "#-------------------------------------------------\n",
    "# Tokenize each of the sentences using nltk:\n",
    "#-------------------------------------------------\n",
    "for i,sentence in enumerate(sentences):\n",
    "    sentences[i] = nltk.word_tokenize(gensim.utils.to_unicode(sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "In addition to `word2vec`, `gensim` provides a doc2vec model that we can use to transform our movie reviews into fixed length vectors. Note that `gensim` assumes a special format for the documents - which I illustrate below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# Convert data into 'documents' for processing by gensim\n",
    "#-------------------------------------------------\n",
    "import gensim\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "documents = [doc2vec.TaggedDocument(doc, [i]) for i, doc in enumerate(sentences)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data properly formatted, we can generate the sentence-level embeddings for the Rotten Tomatoes data using the [gensim](https://radimrehurek.com/gensim/) doc2vec implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# Speed things up with multiprocessing\n",
    "#-------------------------------------------------\n",
    "import multiprocessing\n",
    "CORES = multiprocessing.cpu_count()\n",
    "\n",
    "#-------------------------------------------------\n",
    "# Train Doc2Vec Model, selecting hyper-paramters\n",
    "#-------------------------------------------------\n",
    "doc2vec_model = doc2vec.Doc2Vec(documents    = documents,\n",
    "                                 dm          = 1,    # ({1,0}, optional) – Defines the training algorithm. If dm=1, ‘distributed memory’ (PV-DM) is used. Otherwise, distributed bag of words (PV-DBOW) is employed.\n",
    "                                 dbow_words  = 1,    # ({1,0}, optional) – If 0, use the sum of the context word vectors. If 1, use the mean. Only applies when dm is used in non-concatenative mode.\n",
    "                                 vector_size = 100,  # (int, optional)   – Dimensionality of the feature vectors\n",
    "                                 window      = 8,    # (int, optional)   – The maximum distance between the current and predicted word within a sentence.\n",
    "                                 min_count   = 2,    # (int, optional)   – Ignores all words with total frequency lower than this.\n",
    "                                 epochs      = 10,   # (int, optional)   – Number of iterations (epochs) over the corpus.\n",
    "                                 workers     = CORES # Allows for parallelization across multiple cores of your machine - should speed things up.\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>And just like that - we've trained the doc2vec model. Note that just like `word2vec`, `doc2vec` has several hyper-parameters that will impact the precise nature of the embeddings. I've provided some additional comments next to each of the hyper-parameters that should help clarify what they do. `gensim` also provides a built function that creates the document vectors, given an input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rock rocks :\n",
      " [-1.44153601e-02 -2.39591170e-02  2.69290917e-02  1.95036866e-02\n",
      "  7.44855823e-03 -1.72724389e-02 -1.54242264e-02 -1.25857601e-02\n",
      " -2.89890729e-02  6.63137250e-03  4.52466455e-04  7.94259831e-03\n",
      "  1.89221483e-02  1.85004249e-02 -1.03155021e-02  3.43167712e-03\n",
      " -2.12104619e-02  2.97078281e-03  8.10250174e-03  2.34576147e-02\n",
      "  2.73774359e-02 -3.13795768e-02  3.16853151e-02 -7.49370956e-05\n",
      " -1.85929593e-02  3.14153987e-03 -8.53542425e-03  1.94764752e-02\n",
      "  3.36200086e-04 -6.48112455e-03  2.77458131e-02 -4.89503220e-02\n",
      " -1.34389261e-02 -2.37140339e-03 -1.46882078e-02  6.82174275e-03\n",
      " -7.46581284e-03 -1.24850636e-03  2.46334635e-02 -1.44057879e-02\n",
      " -7.13158213e-03 -3.47599242e-04 -7.98465312e-03 -2.82172728e-02\n",
      " -5.69180846e-02  1.76429693e-02  6.27975038e-04  3.72305624e-02\n",
      " -2.87549570e-02  6.36350140e-02  1.80693567e-02  3.46224234e-02\n",
      " -2.10719015e-02 -2.13983841e-02  6.81256456e-03  3.51674296e-03\n",
      " -2.00131256e-02 -2.89899344e-03 -3.54144052e-02 -8.41913186e-03\n",
      " -1.02236997e-02 -1.23161655e-02  1.93466451e-02  3.37440148e-02\n",
      " -9.48262122e-03 -4.62046638e-03 -3.15382681e-03 -1.34678809e-02\n",
      "  2.24242769e-02  2.08869297e-02  8.90595373e-03  1.53319966e-02\n",
      "  6.45446545e-03 -1.46984383e-02  2.89822500e-02 -2.99362708e-02\n",
      " -5.68891829e-03 -1.29439915e-02 -3.55444923e-02 -2.05463991e-02\n",
      "  1.30145252e-02  3.21761263e-03 -2.04225630e-02 -5.16078871e-05\n",
      " -1.16634304e-02  6.80839550e-03 -1.73792448e-02 -1.59660671e-02\n",
      " -9.98928305e-03 -3.09292134e-03 -1.14890269e-03  7.28358561e-03\n",
      " -8.41797050e-03 -5.28046936e-02  2.84367008e-03 -1.96834709e-02\n",
      " -1.76002737e-02 -4.81031195e-04 -4.46822168e-03 -6.37571421e-03] \n",
      "\n",
      "and so he went a very very long way :\n",
      " [ 0.03234102 -0.02780844  0.01840614  0.01336837 -0.03641032 -0.01228093\n",
      " -0.05846445 -0.03926534 -0.04072861  0.00788521 -0.02473914 -0.0051234\n",
      "  0.03190644  0.01915967  0.00681202 -0.02029229  0.01120864  0.00297469\n",
      "  0.02368575  0.03396758  0.0142144  -0.03766917  0.03947093  0.00145808\n",
      " -0.00984298 -0.01031407 -0.04252528  0.02815702 -0.01202014 -0.03029591\n",
      "  0.03419393 -0.04690094 -0.03711804  0.01276159 -0.01032663 -0.01644801\n",
      " -0.04834871  0.00827292  0.01310829  0.01244174  0.04634966  0.02230377\n",
      " -0.03264895 -0.01924306 -0.06345259 -0.02444755  0.0288558   0.03541097\n",
      " -0.04652775  0.06311798  0.05332647  0.02712234 -0.00801376  0.00475863\n",
      "  0.02618283  0.00858885 -0.03076001 -0.00793097 -0.07185102 -0.00655368\n",
      " -0.03535531  0.01297826 -0.00406259  0.01637292 -0.02858165 -0.01591338\n",
      "  0.01125251  0.00736142  0.00888701 -0.00073327 -0.0168142   0.00808646\n",
      "  0.03792195 -0.03302475  0.00269378 -0.04251285 -0.00364448 -0.00172578\n",
      " -0.03716919 -0.02140551  0.01953426  0.01016723 -0.01392643  0.00594669\n",
      "  0.01236657  0.00203689 -0.02855392 -0.02416155 -0.0334513  -0.0050059\n",
      "  0.01290792  0.02321465  0.02189524 -0.05395974 -0.02449434 -0.05305198\n",
      " -0.01198562 -0.02077582  0.00390313 -0.04204211]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "document = \"The rock rocks\"\n",
    "vector = doc2vec_model.infer_vector(nltk.word_tokenize(gensim.utils.to_unicode(document)))\n",
    "print(document,':\\n', vector,'\\n')\n",
    "\n",
    "document = \"and so he went a very very long way\"\n",
    "vector = doc2vec_model.infer_vector(nltk.word_tokenize(gensim.utils.to_unicode(document)))\n",
    "print(document,':\\n', vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br> Notice that this representation for both \"documents\" are 100 dimensional, just as we requested. Now let's cast each of our document vectors to a fixed length representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Dimentions of our document vector matrix\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10662, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------------------------            \n",
    "# Generate Vector Representations of the documents\n",
    "#--------------------------------------------------------\n",
    "vectors = []\n",
    "for sentence in sentences:\n",
    "    vectors.append(doc2vec_model.infer_vector(sentence))\n",
    "vectors = np.array(vectors)\n",
    "\n",
    "print('-------------------------------------------------------')\n",
    "print('Dimentions of our document vector matrix')\n",
    "print('-------------------------------------------------------')\n",
    "np.shape(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "## Learning Exercise 2: \n",
    "#### Worth 1/5 Points\n",
    "#### A. Use Doc2Vec Features for Rotten Tomatoes Classification\n",
    "Train a simple Logistic Regression model using `sklearn` that uses Doc2Vec features to predict the Rotten tomatoes movie reviews class. Use an 80%-20% training-test split of the data. Try 3-5 configurations of the doc2vec hyper-parameters (the exact settings are up to you) and report the AUROC of the logistic regression for each setting of the hyper-parameters. Comment on any differences you observe in the performance of the model as a function of the hyper-parameters settings and comment on why this might be the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# INSERT YOUR CODE HERE\n",
    "# DO NOT FORGET TO PRINT YOUR MEANINGFUL RESULTS TO THE SCREEN.\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> INSERT AN INTERPRETATION OF YOUR RESULTS HERE </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Creating Document Vectors from Word Vectors\n",
    "Train a `word2vec` model (with hyper-parameter settings of your choice) using the Rotton Tomatoes movie reviews. For each document, construct a fixed size document vector from the word vectors in the document. For instance, if you have a set of five 100-dimensional vectors that describe the five words in a review, you should combine those into one 100 dimensional vector. Propose a way to combine the vectors assuming that you want to use the vectors for review classification; justify your method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# INSERT YOUR CODE HERE\n",
    "# DO NOT FORGET TO PRINT YOUR MEANINGFUL RESULTS TO THE SCREEN.\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> INSERT AN INTERPRETATION OF YOUR RESULTS HERE </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Comparing Embeddings through Visualization\n",
    "Project the best performing doc2vec embedding from **part A** and the vectors you generated in **part B** into two dimensional representations using t-SNE or PCA. Use the `matplotlib` `scatter` function to compare the 2D representations from part A to part B. More specifically, please visualize each document as a point in two-dimensional space and color each document (i.e. point) according to it's class (e.g. positive reviews colored red, and negative reviews colored blue). Comment on differences you observe (if any) and reflect on why these differences (if any) might exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# INSERT YOUR CODE HERE\n",
    "# DO NOT FORGET TO PRINT YOUR MEANINGFUL RESULTS TO THE SCREEN.\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> INSERT AN INTERPRETATION OF YOUR RESULTS HERE </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1><span style=\"color:red\"> Self Assessment </span></h1>\n",
    "Please provide an assessment of how successfully you accomplished the learning exercises in this assignment according to the instruction provided; do not assign yourself points for effort. This self assessment will be used as a starting point when I grade your assignments. Please note that if you over-estimate your grade on a given learning exercise, you will face a 50% penalty on the total points granted for that exercise. If you underestimate your grade, there will be no penalty.\n",
    "\n",
    "* Learning Exercise: \n",
    "    * <span style=\"color:red\">X</span>/1 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
